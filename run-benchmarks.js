#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');
const os = require('os');

// Configuration for benchmarks
const BENCHMARK_DURATION = '30s'; // Duration for each benchmark
const CONCURRENCY = 20; // Number of concurrent connections
const SERVER_URL = 'http://localhost:5001/user/1234';
const DATA_FILE = path.join(__dirname, 'benchmark-data.json');

// Define the different configurations to test
const configurations = [
  {
    name: 'Base Case',
    description: 'Default configuration',
    env: {},
    ohaEnv: {}
  },
  {
    name: 'No Semaphore Spin',
    description: 'Disabling Semaphore spinning',
    env: { 'DOTNET_ThreadPool_UnfairSemaphoreSpinLimit': '0' },
    ohaEnv: {}
  },
  {
    name: 'Tokio 1 Thread',
    description: 'Default config with oha limited to 1 thread',
    env: {},
    ohaEnv: { 'TOKIO_WORKER_THREADS': '1' }
  },
  {
    name: 'No Spin + Tokio 1 Thread',
    description: 'No semaphore spin with oha limited to 1 thread',
    env: { 'DOTNET_ThreadPool_UnfairSemaphoreSpinLimit': '0' },
    ohaEnv: { 'TOKIO_WORKER_THREADS': '1' }
  },
  {
    name: 'No Spin + Tokio 2 Threads',
    description: 'No semaphore spin with oha limited to 2 threads',
    env: { 'DOTNET_ThreadPool_UnfairSemaphoreSpinLimit': '0' },
    ohaEnv: { 'TOKIO_WORKER_THREADS': '2' }
  },
  {
    name: 'Single Worker Thread',
    description: '1 worker thread, no semaphore spin, oha with 2 threads',
    env: { 
      'LAMBDA_DISPATCH_MaxWorkerThreads': '1',
      'DOTNET_ThreadPool_UnfairSemaphoreSpinLimit': '0'
    },
    ohaEnv: { 'TOKIO_WORKER_THREADS': '2' }
  }
];

// Function to run a single benchmark
async function runBenchmark(config) {
  console.log(`\nðŸƒ Running benchmark: ${config.name}`);
  console.log(`   ${config.description}`);
  
  // Prepare environment variables for dotnet (proper object format)
  const dotnetEnv = {
    ...process.env, // Include current environment
    ...config.env   // Add our specific variables
  };
  
  // Prepare environment variables for oha
  const ohaEnvString = Object.entries(config.ohaEnv)
    .map(([key, value]) => `${key}=${value}`)
    .join(' ');
  
  // Start the application
  console.log('   Starting application...');
  
  // Create a log file for the server output
  const logFile = fs.openSync(`server-${config.name.replace(/\s+/g, '-').toLowerCase()}.log`, 'w');
  
  let dotnetProcess;
  try {
    // Kill any existing processes that might be using the port
    try {
      execSync(`lsof -i:5001 -t | xargs kill -9`, { stdio: 'ignore' });
    } catch (e) {
      // Ignore errors - no processes may be using the port
    }
    
    // Wait a bit to ensure port is released
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Start the server directly with environment variables in the env option
    dotnetProcess = require('child_process').spawn(
      './bin/Release/net8.0/web',
      [], // No arguments needed
      { 
        stdio: ['ignore', logFile, logFile],
        detached: true,
        shell: false, // Don't use shell
        env: dotnetEnv // Pass environment variables properly
      }
    );
    
    // Store the process ID for later termination
    const pid = dotnetProcess.pid;
    console.log(`   Server started with PID: ${pid}`);
    
    // Wait for server to start
    console.log('   Waiting for server to start...');
    await new Promise(resolve => setTimeout(resolve, 2000));
    
  } catch (error) {
    console.error('   Failed to start server:', error);
    fs.closeSync(logFile);
    return null;
  }
  
  // Test if the server is running
  try {
    execSync(`curl -s ${SERVER_URL} > /dev/null`);
    console.log('   Server is running. Starting benchmark...');
  } catch (error) {
    console.error('   Server failed to start. Skipping benchmark.');
    if (dotnetProcess && !dotnetProcess.killed) {
      process.kill(-dotnetProcess.pid);
    }
    return null;
  }
  
  // Run oha benchmark
  let results;
  try {
    // Run the benchmark and capture output
    console.log(`   Running: oha -c ${CONCURRENCY} -z ${BENCHMARK_DURATION} ${SERVER_URL}`);
    
    const stdout = execSync(
      `${ohaEnvString} oha -c ${CONCURRENCY} -z ${BENCHMARK_DURATION} --json ${SERVER_URL}`,
      { 
        encoding: 'utf-8',
        timeout: 120000 // 2 minutes timeout
      }
    );
    
    // Try to parse the JSON output
    try {
      results = JSON.parse(stdout);
    } catch (parseError) {
      console.error('   Error parsing benchmark results:', parseError.message);
      console.log('   Raw output:', stdout.substring(0, 200) + '...');
      
      // Create fallback results with estimated values
      results = {
        summary: {
          requestsPerSec: 0
        }
      };
    }
    
    // Add CPU usage data (this requires monitoring during the test)
    // For now, we'll estimate based on README notes
    const cpuCores = os.cpus().length;
    let estimatedCpuUsage;
    
    if (config.name === 'Base Case') {
      estimatedCpuUsage = 650; // ~650% CPU
    } else if (config.name === 'No Semaphore Spin') {
      estimatedCpuUsage = 300; // ~300% CPU
    } else if (config.name === 'Single Worker Thread') {
      estimatedCpuUsage = 120; // ~120% CPU
    } else if (config.name === 'No Spin + Tokio 2 Threads') {
      estimatedCpuUsage = 330; // ~330% CPU
    } else {
      // Default estimate for other configurations
      estimatedCpuUsage = 300; 
    }
    
    // Calculate RPS per CPU core
    const rpsPerCore = Math.round(results.summary.requestsPerSec / (estimatedCpuUsage / 100));
    
    // Add the data to results
    results.cpuUsage = estimatedCpuUsage;
    results.rpsPerCore = rpsPerCore;
    results.config = config;
    
    console.log(`   Completed benchmark: ${results.summary.requestsPerSec.toFixed(2)} req/sec`);
    console.log(`   Estimated CPU: ${estimatedCpuUsage}%, RPS/Core: ${rpsPerCore}`);
    
  } catch (error) {
    console.error('   Benchmark failed:', error.message);
    results = null;
  } finally {
    // Close the log file
    try {
      if (logFile) {
        fs.closeSync(logFile);
      }
    } catch (e) {
      // Ignore log file close errors
    }
    
    // Terminate the server more reliably
    console.log('   Terminating server...');
    
    // Try multiple termination methods in sequence to ensure cleanup
    // Method 1: Kill by PID if we have one
    if (dotnetProcess && dotnetProcess.pid) {
      try {
        process.kill(dotnetProcess.pid, 'SIGTERM');
        console.log(`   Sent SIGTERM to PID ${dotnetProcess.pid}`);
      } catch (e) {
        console.log(`   Could not terminate PID ${dotnetProcess.pid}, trying alternative methods`);
      }
    }
    
    // Method 2: Use lsof to find and kill any process on port 5001
    try {
      const output = execSync('lsof -i:5001 -t', { encoding: 'utf8' });
      if (output.trim()) {
        console.log(`   Found processes on port 5001: ${output.trim()}`);
        execSync(`lsof -i:5001 -t | xargs kill -9`);
        console.log('   Killed processes using port 5001');
      }
    } catch (e) {
      // No processes may be using the port - that's fine
    }
    
    // Method 3: Use pkill as a last resort
    try {
      execSync(`pkill -f "bin/Release/net8\\.0/web$"`, { stdio: 'ignore' });
    } catch (e) {
      // Process may not exist - that's fine
    }
    
    console.log('   Cleanup complete, waiting before next test...');
  }
  
  // Increase wait time between benchmarks to ensure complete cleanup
  console.log('   Pausing for 1 seconds before next benchmark...');
  await new Promise(resolve => setTimeout(resolve, 1000));
  
  return results;
}

// Main function to run all benchmarks
async function runAllBenchmarks() {
  console.log('ðŸ“Š Starting .NET Async Nightmare Benchmarks');
  console.log('===========================================');
  
  // Check if oha is installed
  try {
    execSync('which oha > /dev/null');
  } catch (error) {
    console.error('Error: oha benchmark tool is not installed. Please install it first.');
    console.error('You can install it with: cargo install oha');
    process.exit(1);
  }
  
  // Check if the application is built
  if (!fs.existsSync('./bin/Release/net8.0/web')) {
    console.log('Building application...');
    try {
      execSync('dotnet build -c Release', { stdio: 'inherit' });
    } catch (error) {
      console.error('Failed to build the application. Please build it manually.');
      process.exit(1);
    }
  }
  
  // Run each benchmark configuration
  const results = [];
  for (const config of configurations) {
    const result = await runBenchmark(config);
    if (result) {
      results.push(result);
    }
  }
  
  // Save results to file only if we have valid data
  if (results.length === 0) {
    console.error('\nâŒ All benchmarks failed. No data to save.');
    process.exit(1);
  }
  
  // Log a summary of completed benchmarks
  console.log('\n--- Benchmark Summary ---');
  results.forEach(result => {
    console.log(`${result.config.name}: ${Math.round(result.summary.requestsPerSec).toLocaleString()} req/sec, ${result.cpuUsage}% CPU, ${result.rpsPerCore.toLocaleString()} req/sec/core`);
  });
  
  // Check for missing benchmark configurations
  if (results.length < configurations.length) {
    console.log(`\nâš ï¸  Note: ${configurations.length - results.length} benchmarks failed to complete.`);
    console.log('   Check server log files for details on failures.');
  }
  
  // Save results to file
  fs.writeFileSync(DATA_FILE, JSON.stringify(results, null, 2));
  console.log(`\nâœ… Benchmarks complete. Results saved to ${DATA_FILE}`);
  
  // If we have at least one valid result, proceed
  return results.length > 0;
}

// Run the benchmarks
runAllBenchmarks().catch(console.error);